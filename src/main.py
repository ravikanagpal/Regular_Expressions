# -*- coding: utf-8 -*-
"""CMPUT 501 A1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LfZAyFs850Fxs0OoY82i5SQkQWH-g0G2
"""


"""Dependencies"""
#installing required dependecies
from nltk import RegexpParser
import os
import pandas as pd
from nltk.tokenize import RegexpTokenizer
import csv
import re
import sys

"""
*   Retrieve data
*   Preprocessing

"""

textfiles = []

# function to retrieve the data from files

def get_data(directory, filename):
  file_name = directory+filename+'.txt'
  print(file_name)
  
  with open(file_name, 'r+')as f:
    text = f.read()
    print(text)

"""possible list of patterns for data retrieval:

"""

#the code below will be used to match the the regular expression patterns. 
regex_match_list = {
    #"month": ["([jJ]an(uary)?|[fF]eb(ruary)?|[mM]arch|[aA]pr(il)?|[mM]ay|[jJ]u((ly?)|(ne?))|[aA]ug(ust)?|[oO]ct(ober)?|([sS]ep(?=\b|t)t?|[nN]ov|[dD]ec)(ember)?)"], 
    
    # this pattern match the months
    "month": ["[jJ]anuary|[fF]ebruary|[mM]arch|[aA]pr(il)?|[mM]ay|[Jj]une|[jJ]uly|[aA]ugust|[oO]ctober|([sS]ept|[nN]ov|[dD]ec)ember"],
    
    #pattern match would you year that have the first digit as 1 or 2. 
    "year": ["(?:1[1-9]|2[0-9])\d{2}"],
    #"year": ["\d{1,4}"],
    
    #pattern matches the time (eg 0900 GMT)
    "time": ["\d{2}:?\d{2}?\s(GMT|hrs|HRS)"],
    
    #pattern matches the the time of the day like 2:00 am or 12:00 midnight
    "time_of_day": ["\d{1,2}:?\d{2}\s?([aA].?[mM].?|[Pp].?[mM].?|midnight|noon)"],
    
    #pattern to match the month relative year example Feburary this year
    "month, relative-year": ["([jJ]an(uary)?|[fF]eb(ruary)?|[mM]ar(ch)?|[aA]pr(il)?|[mM]ay|[jJ]u((ly?)|(ne?))|[aA]ug(ust)?|[oO]ct(ober)?|([sS]ep(?=\b|t)t?|[nN]ov|[dD]ec)(ember)?)\s+(this|last|next)\s+year"],
    
    #pattern to match the relative-year month week (eg: next month )
    "relative-year/month/week": ["next\s+(?:week(end)?|month|year)|this\s+(?:week(end)?|month|year)|last\s+(?:week(end)?|month|year)"],
   
    # pattern to show the decade
    "decade": ["the\s+((?:19|20)\d)0s"], 
    
    #matches the part-of-decade (eg: the late 1980's)
    "part-of-decade":["([tT]he\s+(late|mid|early)\s19\d{2}'?s)"],
    
    #matches the day of a week
    "dayofweek" : ["([sS]un|[mM]on|[tT]ues|[wW]ednes|[tT]hurs|[fF]ri|[sS]atur)day"],
    
    #matches the part-of-relative-year month week (eg: late next year)
    "part-of-relative-year/month/week" : ["(earlier|late(r)?|early)\s+(this|next|last)\s+(week|month|year)"],
    
    #this match the quater year (eg: fourth qauter of 2020)
    "quater-year": ["(first|second|third|fourth|last)\s+quarter of\s+((?:19|20)\d{2})"],
    
    #this match the day of month (eg: Feburary )
    "day-month": ["(([0-9])|([0-2][0-9])|([3][0-1]))-?\s?([jJ]an(uary)?|[fF]eb(ruary)?|[mM]ar(ch)?|[aA]pr(il)?|[mM]ay|[jJ]u((ly?)|(ne?))|[aA]ug(ust)?|[oO]ct(ober)?|([sS]ep(?=\b|t)t?|[nN]ov|[dD]ec)(ember)?)"],
    
    # match month day e(eg: Feburary 19 or Feburary-19)
    "month-day": ["([jJ]an(uary)?|[fF]eb(ruary)?|[mM]ar(ch)?|[aA]pr(il)?|[mM]ay|[jJ]un(e)?|[jJ]ul(y)?|[aA]ug(ust)?|[sS]ep(t(ember)?)?|[oO]ct(ober)?|[nN]ov(ember)?|[dD]ec(ember)?)\s?-?(([0-2][0-9])|([3][0-1])|([0-9]))"],
    
    #match month year (eg: May, 2020 or May 2003)
    "month-year": ["([jJ]an(uary)?|[fF]eb(ruary)?|[mM]ar(ch)?|[aA]pr(il)?|[mM]ay|[jJ]u((ly?)|(ne?))|[aA]ug(ust)?|[sS]ep(t(ember)?)?|[oO]ct(ober)?|[nN]ov(ember)?|[dD]ec(ember)?),?-?\s?((?:19|20)\d{2})"],
    
    #match the day month year (eg: 12 June 2010)
    "day-month-year": ["((\d{1,2})\s([jJ]an(uary)?|[fF]eb(ruary)?|[mM]ar(ch)?|[aA]pr(il)?|[mM]ay|[jJ]u((ly?)|(ne?))|[aA]ug(ust)?|[oO]ct(ober)?|([sS]ep(?=\b|t)t?|[nN]ov|[dD]ec)(ember)?),?\s?((1[6-9]|[2-9]\d)\d{2}))"],
    
    #match patterns like the last four days.
    "relative-years/months/weeks/days": ["the last\s+\d{0,2}\s*[a-zA-Z0-9]*\s?(years|months|weeks|days)"],
     }


# this method will
#Input: the id of file, expression type, text and regular expression pattern to match
#output: find the regex pattern and will return the the tuple of id, expression type, matching_string and offset start and ending offset.
##https://stackoverflow.com/questions/4664850/how-to-find-all-occurrences-of-a-substring/4664889#4664889

def find_pattern(id, exp_type, text, regpattern):
  return [(id, exp_type, text[p.start():p.end()], p.start(), p.end()) for p in re.finditer(regpattern, text)]

#the method id useful as it will only consider the date of largest length. Example: It would consider 23 July 2003 instead of only July 2003.
# the method is checking if the start and end offset of a given word likes between any other word offset (start and end) - then it will consider the one with largest offset
def check_subOffsets(df):
  df1 = pd.DataFrame(columns=['article_id', 'expr_type', 'value', 'offset', 'ends'])
  start_i = 0
  while start_i < len(df.index):
      for index, row in df.iterrows():

        if not start_i==index:
            if (row['offset']>= df['offset'][start_i] and row['ends']<=df['ends'][start_i]):

                df1 = df1.append(df.iloc[index])
          
      start_i = start_i+1

  df.drop(df1.index, inplace = True)
  
  return df

#this method contains the pandas dataframe and then call check_suboffset() to get the match of biggest length
def form_dataframe(data):
  df = pd.DataFrame(data, columns =['article_id', 'expr_type', 'value', 'offset', 'ends'])
  df = check_subOffsets(df)
  return df

#test function for find_pattern method
def pattern_from_file(id, filename):
  with open(filename, 'r+', encoding='windows-1252')as f:
    text = f.read()
    l = []
    for exp_type, pattern in regex_match_list.items():
      for p in pattern:
        res = find_pattern(id, exp_type, text, p)
        if len(res)>0:
          l= l+res
          #print(l)
    d = form_dataframe(l)
    #print(d)

    return d

"""###############################################RUN TEST"""

#directory = '/f2021-asn1-JauraSeerat/data/dev/'
directory = str(sys.argv[1])
results_list = []
for filename in os.listdir(directory):
      if filename.endswith(".txt"): 
        id = re.findall("\d+\.txt", filename)[0]
        file_name = directory+filename
        results_list.append(pattern_from_file(id, file_name))
result = pd.concat(results_list)

result.sort_values(by=['article_id'],ascending=True)
result = result.drop('ends', 1)
result.head(5)

outputfile = str(sys.argv[2])
result.to_csv( outputfile, index=False)


